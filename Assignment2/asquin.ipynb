{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pedestrians recognition without using Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import glob\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "\n",
    "data_root = \"img1\"\n",
    "BACK_SUB_FOLDER_PATH = \"back_sub\"\n",
    "MAX_DIST_CONSIST = 8\n",
    "N_CONSISTENCY = 3\n",
    "\n",
    "gt_path = './gt/gt.txt'\n",
    "\n",
    "_W = 1280\n",
    "_H = 960\n",
    "_N = 684 # number of frames\n",
    "\n",
    "WIDTH_SAMPLE_SVM = 15\n",
    "HEIGHT_SAMPLE_SVM = 30\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and dataset function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_id(frame):\n",
    "    assert _N >= frame\n",
    "    return '{:03d}'.format(frame)\n",
    "\n",
    "\n",
    "def read_frame(root, frame):\n",
    "    \"\"\"Read frames and create integer frame_id-s\"\"\"\n",
    "    assert _N >= frame\n",
    "    return cv2.imread(os.path.join(root,format_id(frame)+'.jpg'), cv2.IMREAD_UNCHANGED)\n",
    "    \n",
    "\n",
    "def read_gt(filename):\n",
    "    \"\"\"Read gt and create list of bb-s\"\"\"\n",
    "    assert os.path.exists(filename)\n",
    "    with open(filename, 'r') as file:\n",
    "        lines = file.readlines()\n",
    "    # truncate data (last columns are not needed)\n",
    "    return [list(map(lambda x: int(x), line.split(',')[:6])) for line in lines]\n",
    "\n",
    "\n",
    "def annotations_for_frame(solution, frame):\n",
    "    assert _N >= frame\n",
    "    return [bb for bb in solution if int(bb[0])==int(frame)]\n",
    "\n",
    "\n",
    "def evaluate_solution(gt, solution, N):\n",
    "    \"\"\"Caclulate evaluation metric\"\"\"\n",
    "    score = []\n",
    "    #for frame in [300]:\n",
    "    for frame in range(1, N):\n",
    "        bbs_sol = annotations_for_frame(solution, frame)\n",
    "        bbs_gt = annotations_for_frame(gt, frame)\n",
    "        black_sol = np.zeros((_H, _W))\n",
    "        black_gt = np.zeros((_H, _W))\n",
    "        for bb in bbs_sol:\n",
    "            x, y = bb[2:4]\n",
    "            dx, dy = bb[4:6]\n",
    "            cv2.rectangle(black_sol, (x, y), (x+dx, y+dy), (255), -1)\n",
    "        for bb in bbs_gt:\n",
    "            x, y = bb[2:4]\n",
    "            dx, dy = bb[4:6]\n",
    "            cv2.rectangle(black_gt, (x, y), (x+dx, y+dy), (255), -1)\n",
    "        # intersection over union\n",
    "        intersection = black_sol * black_gt\n",
    "        intersection[intersection > 0.5] = 1\n",
    "        union = black_sol + black_gt\n",
    "        union[union > 0.5] = 1\n",
    "        if not union.any():\n",
    "            continue\n",
    "        score.append(intersection.sum()/union.sum())\n",
    "        \n",
    "        \n",
    "    return np.asarray(score).mean()\n",
    "    \n",
    "\n",
    "def show_annotation(solution, frame):\n",
    "    assert _N >= frame\n",
    "    im = read_frame(data_root, frame)\n",
    "    bbs = annotations_for_frame(solution, frame)\n",
    "    for bb in bbs:\n",
    "        x, y = bb[2:4]\n",
    "        dx, dy = bb[4:6]\n",
    "        cv2.rectangle(im, (x, y), (x+dx, y+dy), (0,255,0), 10)\n",
    "    plt.imshow(im)\n",
    "    plt.title('Annotations for frame {}.'.format(frame))\n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HOG function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hog(im_path):\n",
    "    hog = cv2.HOGDescriptor()\n",
    "    im = cv2.imread(im_path)\n",
    "    h = hog.compute(im)\n",
    "    print(h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def disp_image(im):\n",
    "    imgplot = plt.imshow(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background substraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def background_substraction(les_im_path, video_name=None, back_sub_folder=\"back_sub\"):\n",
    "    \"\"\"\n",
    "    Generate a video with background substraction\n",
    "    :param les_im_path: list of string, images path\n",
    "    :param video_name: string, default = None, if set, will save a video of the backgroud substraction to 'video_name'.avi\n",
    "    :param back_sub_folder: string, default = 'back_sub', folder used to save background substracted images\n",
    "    \n",
    "    OUTPUT:\n",
    "        back_sub/XXX.jpg : images of the background substraction\n",
    "        \n",
    "        if video_name != None:\n",
    "            video_name.avi : video of the background substraction\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create background frame\n",
    "    fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "    \n",
    "    # Create output folder if doesn't already exist\n",
    "    try:\n",
    "        os.mkdir(back_sub_folder)\n",
    "    except FileExistsError:\n",
    "        pass\n",
    "    \n",
    "    if video_name is not None:\n",
    "        # Get video size\n",
    "        height,width,layers=cv2.imread(les_im_path[0]).shape\n",
    "\n",
    "        # Create video object\n",
    "        fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "        video = cv2.VideoWriter(video_name + '.avi', fourcc, fps=25, frameSize=(width,height), isColor=False)\n",
    "    \n",
    "    # Computing background\n",
    "    for im_path in les_im_path:\n",
    "        im = cv2.imread(im_path)\n",
    "        fgmask = fgbg.apply(im)\n",
    "        \n",
    "        cv2.imwrite(back_sub_folder + '/' + im_path.split(\"/\")[-1], fgmask)\n",
    "        \n",
    "        if video_name is not None:\n",
    "            # Writing frame to video\n",
    "            video.write(fgmask)\n",
    "    \n",
    "    if video_name is not None:\n",
    "        # Close video\n",
    "        video.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get human shaped contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Box:\n",
    "    def __init__(self, x_min, y_min, x_max, y_max):\n",
    "        self.x_min = x_min\n",
    "        self.y_min = y_min\n",
    "        self.x_max = x_max\n",
    "        self.y_max = y_max\n",
    "    \n",
    "    def __repr__(self):\n",
    "        ret = \"x_min\" + str(self.x_min) + \", y_min\" + str(self.y_min) + \", x_max\" + str(self.x_max) + \", y_max\" + str(self.y_max)\n",
    "        return ret\n",
    "    \n",
    "    def is_overlap(self, other):\n",
    "        return not (self.x_max < other.x_min or self.x_min > other.x_max or self.y_max < other.y_min or self.y_min > other.y_max)\n",
    "\n",
    "        \n",
    "def filter_ratio(box, ratio_min, ratio_max, disp=False):\n",
    "    width = box.x_max - box.x_min\n",
    "    height = box.y_max - box.y_min\n",
    "\n",
    "    # ratio\n",
    "    ratio = height / width\n",
    "\n",
    "    if ratio > ratio_min and ratio < ratio_max:\n",
    "        return box\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "        \n",
    "def get_contours_human_ratio(im_path, disp=False):\n",
    "    # Load image and resize witout changing ratio\n",
    "    im = cv2.imread(im_path)\n",
    "    height, width = im.shape[:2]\n",
    "    new_width = 500\n",
    "    new_height = new_width*height//width\n",
    "    im = cv2.resize(im,(new_width, new_height), interpolation = cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Change to gray and apply both gaussian and threshold filter\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    blurred_im = cv2.GaussianBlur(im_gray, (1, 1), 0)\n",
    "    ret,thresh = cv2.threshold(blurred_im, 220, 255, 0)\n",
    "    \n",
    "    # Compute contours\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Get dimension of main contours\n",
    "    les_potential_human_box = []\n",
    "    for cnt in contours:\n",
    "        # Compute area size\n",
    "        area = cv2.contourArea(cnt)\n",
    "        if area > 3:\n",
    "            # remove overdimension of contours\n",
    "            cnt_low = cnt[:, 0]\n",
    "            \n",
    "            if disp:\n",
    "                print(area)\n",
    "                im2 = cv2.drawContours(im.copy(), cnt, -1, (255,0,0), 2)\n",
    "                disp_image(im2)\n",
    "    \n",
    "            # contour width\n",
    "            x_max = np.max(cnt_low[:, 0])*width//new_width\n",
    "            x_min = np.min(cnt_low[:, 0])*width//new_width\n",
    "            # contour height\n",
    "            y_max = np.max(cnt_low[:, 1])*height//new_height\n",
    "            y_min = np.min(cnt_low[:, 1])*height//new_height\n",
    "            \n",
    "            potential_human_box = filter_ratio(Box(x_min, y_min, x_max, y_max), 1, 5)\n",
    "            if potential_human_box is not None:\n",
    "                les_potential_human_box.append(potential_human_box)\n",
    "            \n",
    "    return les_potential_human_box\n",
    "    \n",
    "    \n",
    "a = get_contours_human_ratio(BACK_SUB_FOLDER_PATH + \"/220.jpg\", disp=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting persons\n",
      "Done                    \n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class SVM:\n",
    "    \n",
    "    def __init__(self, les_im_path, replace=False, load_in_ram=True):\n",
    "        self.gt = read_gt(gt_path)\n",
    "        self.dataset_svm_path = \"dataset_svm\"\n",
    "        self.dataset_svm_neg_path = self.dataset_svm_path + \"_neg\"\n",
    "        \n",
    "        self.les_im_path = les_im_path\n",
    "        self.load_in_ram = load_in_ram\n",
    "        if self.load_in_ram:\n",
    "            self.persons = []\n",
    "            self.negative = []\n",
    "        \n",
    "        if replace:\n",
    "            # Remove dataseth\n",
    "            if os.path.isdir(self.dataset_svm_path):\n",
    "                shutil.rmtree(self.dataset_svm_path)\n",
    "            # remove negative dataset\n",
    "            if os.path.isdir(self.dataset_svm_neg_path):\n",
    "                shutil.rmtree(self.dataset_svm_neg_path)\n",
    "            \n",
    "            # Create empty dataset folders\n",
    "            os.mkdir(self.dataset_svm_path)\n",
    "            os.mkdir(self.dataset_svm_neg_path)\n",
    "            \n",
    "            self.dataset_prepare()    \n",
    "    \n",
    "    def write_random_areas(self, frame_path, frame, les_box):\n",
    "        \"\"\"\n",
    "        For SVMs, we have to generate negative samples. Thus, we need to generate images where there is not human\n",
    "        \"\"\"\n",
    "        frame_height, frame_width = frame.shape[:2]\n",
    "        \n",
    "        for id_box, box in enumerate(les_box):\n",
    "            \n",
    "            box_width = box.x_max - box.x_min\n",
    "            box_height = box.y_max - box.y_min\n",
    "            \n",
    "            target_is_ok = False\n",
    "            while not target_is_ok:\n",
    "                x_min_target = random.randint(0, frame_width - box_width-1)\n",
    "                y_min_target = random.randint(0, frame_height - box_height-1)\n",
    "                \n",
    "                box_target = Box(x_min_target, y_min_target, x_min_target + box_width, y_min_target + box_height)\n",
    "                \n",
    "                # Check if target box and other boxes are overlapping\n",
    "                for box2 in les_box:\n",
    "                    if not box2.is_overlap(box_target):\n",
    "                        # Stopping while\n",
    "                        target_is_ok = True\n",
    "                        # get neg image crop\n",
    "                    else:\n",
    "                        # If overlap, break the for loop to not reach write specs and set false ok target\n",
    "                        target_is_ok = False\n",
    "                        break\n",
    "                        \n",
    "                im_crop = frame[box_target.y_min:box_target.y_max, box_target.x_min:box_target.x_max]\n",
    "                im_crop = cv2.resize(im_crop,(WIDTH_SAMPLE_SVM,HEIGHT_SAMPLE_SVM))\n",
    "                \n",
    "                crop_path = self.dataset_svm_neg_path + '/' + frame_path.split(\"/\")[-1].replace(\".jpg\", \"_\" + str(id_box) + \".jpg\")\n",
    "                cv2.imwrite(crop_path, im_crop)\n",
    "\n",
    "                if self.load_in_ram:\n",
    "                    self.negative.append(im_crop)\n",
    "\n",
    "    \n",
    "    def dataset_prepare(self):\n",
    "        print(\"Extracting persons\")\n",
    "        for id_frame, frame_path in enumerate(self.les_im_path):\n",
    "            print(\"Frame #\" + str(id_frame), end=\"\\r\")\n",
    "            bbs_gt = annotations_for_frame(self.gt, id_frame)\n",
    "            black_gt = np.zeros((_H, _W))\n",
    "            frame = cv2.imread(frame_path)\n",
    "            \n",
    "            les_box = []\n",
    "            for id_bb, bb in enumerate(bbs_gt):\n",
    "                x, y = bb[2:4]\n",
    "                dx, dy = bb[4:6]\n",
    "                les_box.append(Box(x, y, x+dx, y+dy))\n",
    "                \n",
    "                im_crop = frame[y:y+dy, x:x+dx]\n",
    "                im_crop = cv2.resize(im_crop,(WIDTH_SAMPLE_SVM,HEIGHT_SAMPLE_SVM))\n",
    "                \n",
    "                crop_path = self.dataset_svm_path + '/' + frame_path.split(\"/\")[-1].replace(\".jpg\", \"_\" + str(id_bb) + \".jpg\")\n",
    "                cv2.imwrite(crop_path, im_crop)\n",
    "                if self.load_in_ram:\n",
    "                    self.persons.append(im_crop)\n",
    "                \n",
    "            self.write_random_areas(frame_path, frame, les_box)\n",
    "        print(\"Done\" + \" \"*20)\n",
    "                \n",
    "                \n",
    "    \n",
    "    def dataset_split(self):\n",
    "        X_train, X_test, y_train, y_test = train_test_split(data_images, digits.target)\n",
    "        print('Training data and target sizes: \\n{}, {}'.format(X_train.shape, y_train.shape))\n",
    "        print('Test data and target sizes: \\n{}, {}'.format(X_test.shape, y_test.shape))\n",
    "\n",
    "svm = SVM(tester.les_im_path, replace = True, load_in_ram=False)\n",
    "# svm.dataset_prepare(tester.les_im_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAHwAAAD8CAYAAAC1rsBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAEi1JREFUeJztnX+IZNlVx7+nXlV3T/eubEY3YbOzmPwxSPKPKyxLIAgSDYxR3PyhkFVEYcG/hIQEzKggCv6x/qP5R5RFl4wgGYMKLiEgw5glCBJ3k2h+LZudLMQMu2QMZtnNTndXV9Xxj3ozXfd7T9e9/br7Vfee84Gi5725771bdd5997xzz/1eUVUEfhisugJBv4TBnREGd0YY3BlhcGeEwZ0RBndGGNwZRzK4iFwSkRdF5IaIXD6uSgUnh3SNtIlIA+DbAD4I4CaA5wA8rqrfOuiY+7ZG+s7z63e3rWvzvtK2tU9Eku0BbQPAoEnvdZF0u/vvQnWbcf2NYwZ8UFpoVlGXF1/Z/oGq3l8qNyye6WAeBXBDVV8GABG5CuAxAAca/J3n1/F3H3v47vZ0tpeVmYx30+3JJNkej8fZMbxvNEy/1sbGRnbM1tZWsr2+vp5sT/am2THZzYdZVmZI1x7vpt+Rvw8ArK2tJduzWXre3d30N7Gu/bN/9PXvZoUMjvJIfxDA9xa2b7b7glPMUQyePyeB7NkjIr8jIs+LyPM/fDO/u4N+Ocoj/SaAhxa2LwB4hQup6lMAngKA9zx0j8503+jWI3FK98xU0kfroMkr0gzTe48fvdYjcdiMku3RMH2ssh8A5I9a65bnRzafxzrveJweMxym7ZAf+QCwO97JL17BUVr4cwAuisi7RWQNwEcAPHOE8wU90LmFq+pERH4XwL8CaAA8rarfPLaaBSfCUR7pUNXPA/j8MdUl6IGItDnjSC380KhipvtOmCJ/15UBBVFm5JAZpx0M6L6lY/b28vd9fnefTtO6WM4VO4ON4UGyMzWQtEzT5MdMJqkzuEcxgKbJ68JOZy3Rwp0RBndGGNwZvfbhCmCyGLyQvEfmvrPhQQ7N71HhXRQfUTWiNXwIBVWGkv80jSwP8ABAMxhSGRrIMfr94TC9NvsXk0nu61jBmBqihTsjDO6MMLgz+n0PhyZ9Jb9zA9Z4RLqHBzmAvP/lc4jxvt8Ml9/rM8kHdjhJYjbNzztap7HtCQ0G8QAM8jF0HoCx4ghWnKCGaOHOCIM7IwzujDC4M3oePAEGC4EINTKeppTlORqlyYVWsIbHI4bkXG1s5Pc1D7hsb28n25zUCBhBFcNvGu9RAIeuk7tsRlYqOWSTWe4cTtU6U5lo4c4IgzsjDO6MfvtwkSRgkCUuAFBKXphOuH/L+y4+j1BQxRqwGPBsD8KaMMD71jfuWXoOwJgFYwy48DfSikzXCLwEVYTBnREGd0YY3Bm9B14Sp6wiM5SdEyMGAcFyJ8dyDjl7tGnSn8LyiXhUznLsSlhZMiUHjEfTAPs71RAt3BlhcGeEwZ2x0owXswTP7jBmajDcBx6HTAhnywJ5AMeahlyaHmz119wfd/kNaokW7owwuDPC4M7od+aJprM07ffLtL+azZb3tRb8rs4yIvPzLPclOEMVAJSSDmxpr+X+hOkb5BdPz2Hk8vJs11qihTsjDO6MosFF5GkRuSUi31jYd15EronIS+3ft51sNYPjoqaFfxrAJdp3GcB1Vb0I4Hq7HZwBik6bqn5RRN5Fux8D8HPtv68AeBbAJ2suuOjEWE7bdLp8gMLy2bLBEvp/a6AhD7SkzqJVtyxotFuW5+RjrCBKKThjZez07bS9Q1VfBYD279s7nifomRN32halN1+7HdKbq6arwb8vIg8AQPv31kEFVfUpVX1EVR+5b7Pn0H2Q0dUCzwD4LQBPtn//pf7Q/f6J+2vAmPpbMfjAlPpRq0ypT7cYGX0rX4v10mVmBGvoNLneuyH1VRiEOoia17LPAPgPAD8lIjdF5AnMDf1BEXkJc4H8JztdPeidGi/98QP+6+ePuS5BD0SkzRm9e1GL/ZOVQMCcO3cu2bbeqbM+mkZPrHdWVtHgMjXX4brNz5uemH2FmuTDmgSOLgmUQLRwd4TBnREGd0YY3BkrddpqBhLYObEcJS7Dd7F1HXbARqNUf7zGueJjrLrUzFYZDXjWC2e85E6ntdhPDdHCnREGd0YY3Bk9S36k/VOXxWYt3dEsM3RYXmeEr1wT7GAm07wuDPsCNb4B9/tWf20laNQQLdwZYXBnhMGd0WsfLpBELsvqJjkpIl84Nl9kNe8n0/djM1kyW8i9nDSR19VIYiQRLtZlt2aelPyUodEuu84ojRbujDC4M8LgzgiDO6P3wZNFB8tyjEryHdbgAztlWeao4R2yo8cOWI3TZi0220Xyg6/N39GaLlwTGLKIFu6MMLgzwuDO6L0PL/U93MXVyIJngYtJmg1rLYjH/X4m8WlpfDKWbAjvy7at6a/Lj1Fjgd3IWg2qCIM7IwzujJX24TWzOhlznZTC4IP17suDDzWzUrusM1KTWMHfqSa5oSZOYBEt3BlhcGeEwZ0RBndG73rpSVDBClxYK7guYGVwZtkqBemv+TEsLVK+9/PgzOGdzppBD3YoY7pw0JkwuDNqRH0eEpEviMgLIvJNEflouz/0Vs8gNX34BMAnVPUrInIvgC+LyDUAv4253uqTInIZc73VovzmYYMXTcVoCi+4Pqla8ySrGV3Gkuukxd87BD9qkj4Yq/4nFnhR1VdV9Svtv98A8AKABzHXW73SFrsC4MOdahD0yqH68FZk92cAfAmht3omqTa4iNwD4J8AfExVXz/Ecftaq2+G1uqqqTK4iIwwN/bfq+o/t7ur9FYTrdWt0FpdNUULyNyj+FsAL6jqny/8Vwe9VYEsCIsOLGdEC86IEZgZkFjp+ij9WtboU7LoLQBlrdVBLufB8HUAYGd3m65T1n/jn6HGIdvc3CyWsahpcu8H8JsAvi4i/9Xu+wPMDf3ZVnv1fwD8WqcaBL1So7X67+B3ln1Cb/WMEZE2Z/Q8XTi9w7jfBIBBaf0PY+whC0yQvrilNy58r5NvkP0/8qm/wyav/2iW9v01GS+lmTKWPNj6+nq2r4Zo4c4IgzsjDO6MlUZCrEEDKchaWfkR3C3yKazcBpbmmPL6YsP8oGyWqhqJFbyjMBt2XoTXKVu+gDwQCRBBJWFwZ4TBnREGd8bpc9oqnJwS7PRY1+EsGQ5+mAMYlGXbVOimspyH9X2aZrkZrLrULBBkES3cGWFwZ4TBndG/Xvri6IfVP2caqOUF17OxE+GFZK2sVZLpou29mRF4maY/19a5jaxMPlWZ5cGsgMnyJAnh1WgBDCpmylhEC3dGGNwZYXBnnDrpTQX3v8cwY9MYcOH34+x92VhbJZPmGJRn0aytrSXbNdKb/B3FyDDrIj8CRAt3RxjcGWFwZ4TBnXHq5v5kDhY5J9bCMtk5WM5jagVeaLCEgjM6ywMku2NyKM2BEMqYJUfPDBzNljtgM0svfekRBxMt3BlhcGeEwZ2x0gXju5SvOb5mQVflvrUgFwbkAZ4a3ddSgGcOzVxlP6DjQIlFtHBnhMGdEQZ3Rq99uKomCQI1Sgc1CYkMn9VMlgQnS9IMzgqN9e2dfIClNNhjaqFTs5uSH9BUDNLUEi3cGWFwZ9RIb26IyH+KyH+30pt/0u5/t4h8qZXe/AcRWSudK1g9NS18F8AHVPWnATwM4JKIvA/AnwH4C1W9COCHAJ44uWoGx0WNqI8C+FG7OWo/CuADAH693X8FwB8D+KvCubCzs7N/ccOBKWmFVy1QW/h/i6xMxayYoSHb9cYbb6Rl6DvaWbfLh0KGQ2PmzEkuciMiTSvZdQvANQDfAfCa6t0J0jcx118NTjlVBlfVqao+DOACgEcBvMcqZh2bSG/eDunNVXMoL11VXwPwLID3AbhPRO48ry4AeOWAY/alNzdP3fC7O2qkN+8HsKeqr4nIOQC/gLnD9gUAvwrgKqqlN1NMCSvatvo8o5LpMZJ+LWuQI8s54IERS1KMzrO1uZWVef31VHd4OEwlt6bTwwebLLr24TVN7gEAV0SkwfyJ8FlV/ZyIfAvAVRH5UwBfxVyPNTjl1HjpX8NcI533v4x5fx6cISLS5owwuDP61VoVSXRDLcejNLpkOTQcEGkGFSsHF2IxNXIkVl1YA5WnGrFTB+Raqvyda1ZHriVauDPC4M4Igzvj1Ml2cSiGJTQGkld5QP0Zz9SwptvyhXLNdeuQtMyPbm9nZYZrpGNO/fzthcGjO9xL9S/NXrHK1BIt3BlhcGeEwZ3Re9bqos63tZYHv5mzLviakXTAdJHD6HIM+xdAWeLD6nu5j+ZYhDVbxfrtaogW7owwuDPC4M4IgztjpdOFLWdEWVdU03tyMjNS5+i2bWo01nlhugqnLZsubCyAx2vlcrDm3nt+LD8xyY3sjMfJ9shw9EKnLagiDO6MMLgzek6AGGA03B9c2N7OBx+mtPjbGg1GWP1+qT+rmnlSyoiA1Yfn7WV7J12LhAMtm1vn8mPodxjvpecYIF9Y1tZdLxMt3BlhcGeEwZ3RexLjsNkfXBg2eX+c3YH0vrxmzDjlvpRnjdSsfSYFnXYgf6fmBWsBYG09HdTgpMbbt29nx7Du+hotdDse52uUDZpu4pvRwp0RBndGGNwZYXBn9J/xsrfv6MwM2dGZVOiaHUtdMjW39P9hDOwoa6objh05mZMJ67blARMOztRkpMbgSVBFGNwZYXBn9JwAIUnfY82omNL6JLzQqhVEyfrW0qwSg6yMoZ+eFTE0UHlxWZ4gayp1sHb7IA3eWLNtagZ7LKKFOyMM7oxqg7fifF8Vkc+126G1egY5TB/+UQAvALiThXdHa/WqiPw15lqrS6U3Rcrv1RNjduUiptQXd4wV66RwX1uzElimhW4JS3RIxij5GKbs2AlLb14A8EsA/qbdFsy1Vv+xLXIFwIc71SDoldpH+qcA/B72p379OCq1VhPpzTdDenPV1Oil/zKAW6r65cXdRlHzuZRIb26F9OaqqbHA+wH8ioh8CMAG5n34p9Bqrbat/ECt1eB0UWzhqvr7qnpBVd8F4CMA/k1VfwP7WqtArdaqzrNO73xEJPs0TZN8uqCz9FODyIA+ed34Y58nLTNQJJ8Gkn1ms1nyWfyNDvqdVDX51HKU9/BPAvi4iNzAvE8PrdUzwKE6VVV9FnP57NBaPaNEpM0ZvbrNs9ksydpkeQygnAww0/zVLh88KScq8MRPPqYmv8DqO3lmjMjhB274HFaw6kQDL8FbhzC4M8Lgzug/iXG6r24wMJIYRzRTA5TUqIYCRKk/swcsSmUq1i0zrpWts5b5Bpb8d7o9mfAPY61bFjNPggrC4M4IgzsjDO6Mla55YsFOD2utWnRx2oSySLiMdQxnnlgOGNeXncOaRehqZpVY0ic1RAt3RhjcGWFwZ/Scc6TJrM29PWMgpKAvbvXX2RohDc/YzI/hPrAm2WJ3N5XesPwRXkyW+/TNzc3smDFJbfJgycz4nUaDWPMkqCAM7owwuDPC4M7oN/AyGGBjY+PutrXw6vZOqmM2bJYvxAqUR7q6aKHXlNkxpkWxLhtf2wqYsGPH37Hpe6pR8NYhDO6MMLgzeh48AYaj/YDB4r/vsEuLv02m6fb6hpXpmt63NVJfs0wzjDJVKoI1VhnhNsQZqZPyMbxt+Rch2xVUEQZ3RhjcGb1nrS4u0Lr4Tn63QjQbhd9RbfmOdB8nGdjyYHndFrH6Zy4zGub+RCmBw6oLz8Dhax9mdmiJaOHOCIM7IwzujDC4M/p32ib7WSNWgGRtnQYOhjT4kE3DAThowoGYLlN/uzpKrA3LuqmWM1ihrJTtisGToIowuDPC4M6Q43ypL15M5H8BfBfATwD4QW8XPhpnpa4/qar3lwr1avC7FxV5XlUf6f3CHThLda0hHunOCIM7Y1UGf2pF1+3CWaprkZX04cHqiEe6M3o1uIhcEpEXReSGiFzu89o1iMjTInJLRL6xsO+8iFxr13a5JiJvW2Udj0pvBheRBsBfAvhFAO8F8LiIvLev61fyaQCXaN9lANdV9SKA6+32maXPFv4ogBuq+rKqjgFcBfBYj9cvoqpfBPB/tPsxzNd0Ad4Ca7v0afAHAXxvYfvAdVJOGe9Q1VcBoP379hXX50j0afDqdVKCk6NPg98E8NDC9llZJ+X7IvIAALR/b624PkeiT4M/B+Biu6LhGubrpzzT4/W78gzma7oAtWu7nGZ4sZST/AD4EIBvA/gOgD/s89qV9fsMgFcB7GH+RHoC8/VcrgN4qf17ftX1PMonIm3OiEibM8LgzgiDOyMM7owwuDPC4M4IgzsjDO6M/wekFwzLhtvETAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(svm.persons[0].shape)\n",
    "disp_image(svm.persons[4])\n",
    "disp_image(svm.negative[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply boxes to video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_box(les_box):\n",
    "    # If a box is above another, merge\n",
    "    to_process_box = les_box.copy()\n",
    "    les_new_box = []\n",
    "    while len(to_process_box) > 0:\n",
    "        box = to_process_box.pop(0)\n",
    "        # get x domain\n",
    "        les_box_mate = []\n",
    "        for box_mate in les_box:\n",
    "            # If overlap\n",
    "            if box.x_max > box_mate.x_min and box_mate.x_max > box.x_min:\n",
    "                les_box_mate.append(box_mate)\n",
    "                # Remove the soon merged box mate from the list of \"to merge\" boxes\n",
    "                try:\n",
    "                    to_process_box.remove(box_mate)\n",
    "                except ValueError:\n",
    "                    pass\n",
    "        if len(les_box_mate) != 0:\n",
    "            # Get boundaries\n",
    "            x_min_mate = min([box_mate.x_min for box_mate in les_box_mate])\n",
    "            x_max_mate = max([box_mate.x_max for box_mate in les_box_mate])\n",
    "            y_min_mate = min([box_mate.y_min for box_mate in les_box_mate])\n",
    "            y_max_mate = max([box_mate.y_max for box_mate in les_box_mate])\n",
    "            les_new_box.append(Box(x_min_mate, y_min_mate, x_max_mate, y_max_mate))\n",
    "    \n",
    "    return les_new_box\n",
    "\n",
    "\n",
    "def intertia_consistency_box(les_whole_box, max_dist=5, n_consistency=5):\n",
    "    print(\"Checking box inertia and consistancy\")\n",
    "    # looping to check consistency between boxes n and n-1\n",
    "    # check if their is a box in the n+1 frame near to the box studied in the n frame\n",
    "    assert n_consistency > 0\n",
    "    \n",
    "    les_whole_box_intertia = []\n",
    "    for id_les_box in range(0, len(les_whole_box)-n_consistency):\n",
    "        print(\"#\" + str(id_les_box+1) + \"/\" + str(len(les_whole_box)), end=\"\\r\")\n",
    "        les_box_inertia = []\n",
    "        # get the study box\n",
    "        for study_box in les_whole_box[id_les_box]:\n",
    "            # init les_box list\n",
    "            # compute center of studied box\n",
    "            x = (study_box.x_max - study_box.x_min)/2\n",
    "            y = (study_box.y_max - study_box.y_min)/2\n",
    "            for target_box in les_whole_box[id_les_box+1]:\n",
    "                # compute center of targeted box\n",
    "                x_target = (target_box.x_max - target_box.x_min)/2\n",
    "                y_target = (target_box.y_max - target_box.y_min)/2\n",
    "                dist = np.linalg.norm( np.array([x, y]) - np.array([x_target, y_target]) )\n",
    "                if dist < max_dist:\n",
    "                    to_save = False\n",
    "                    # if own a near n+1 frame box, keep the studied box\n",
    "                    # if dual, check on second round\n",
    "                    if n_consistency > 1:\n",
    "                        for target_box_2 in les_whole_box[id_les_box+n_consistency]:\n",
    "                            x_target_2 = (target_box_2.x_max - target_box_2.x_min)/2\n",
    "                            y_target_2 = (target_box_2.y_max - target_box_2.y_min)/2\n",
    "                            dist = np.linalg.norm( np.array([x, y]) - np.array([x_target_2, y_target_2]) )\n",
    "                            if dist < max_dist*n_consistency:\n",
    "                                to_save=True\n",
    "                    else:\n",
    "                        to_save=True\n",
    "                        \n",
    "                    if to_save:\n",
    "                        les_box_inertia.append(study_box)\n",
    "                        break            \n",
    "        \n",
    "        # Store last frame boxes\n",
    "        les_whole_box_intertia.append(les_box_inertia)\n",
    "    print(\"Done\" + \" \"*20)\n",
    "    return les_whole_box_intertia\n",
    "\n",
    "\n",
    "def apply_box_to_video(les_im_path, les_im_backsub_path, video_name=\"apply_box\"):\n",
    "    \n",
    "    height,width,layers=cv2.imread(les_im_path[0]).shape\n",
    "\n",
    "    # Create video object\n",
    "    fourcc = cv2.VideoWriter_fourcc('M','J','P','G')\n",
    "    video = cv2.VideoWriter(video_name + '.avi', fourcc, fps=25, frameSize=(width,height))\n",
    "    \n",
    "    print(\"Computing boxes: ratio -> merging -> ratio\")\n",
    "    les_whole_box = []\n",
    "    # Computing background\n",
    "    for id_im, im_path in enumerate(les_im_path):\n",
    "        print(\"#\" + str(id_im+1) + \"/\" + str(len(les_im_path)), end=\"\\r\")\n",
    "        im = cv2.imread(im_path)\n",
    "        \n",
    "        # Get box\n",
    "        les_box = get_contours_human_ratio(les_im_backsub_path[id_im])\n",
    "        \n",
    "        # Merge box\n",
    "        merged_box = merge_box(les_box)\n",
    "        \n",
    "        # Get ride of out of ratio boxes\n",
    "        les_merged_ratio_box = []\n",
    "        for box in merged_box:\n",
    "            merged_ratio_box = filter_ratio(box, 1, 5)\n",
    "            if merged_ratio_box is not None:\n",
    "                les_merged_ratio_box.append(merged_ratio_box)\n",
    "        \n",
    "        les_whole_box.append(les_merged_ratio_box)\n",
    "    print(\"Done\" + \" \"*20)\n",
    "    \n",
    "    les_whole_box_inertia = intertia_consistency_box(les_whole_box.copy(), max_dist=MAX_DIST_CONSIST, n_consistency=N_CONSISTENCY)\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    print(\"Writing video\")\n",
    "    for id_les_box, les_box in enumerate(les_whole_box_inertia):\n",
    "        print(\"#\" + str(id_les_box+1) + \"/\" + str(len(les_whole_box_inertia)), end=\"\\r\")\n",
    "        # write box into image\n",
    "        im = cv2.imread(les_im_path[id_les_box])\n",
    "        # Write frame id in im\n",
    "        cv2.putText(im, str(id_les_box),(10,height), font, 3,(255,255,255),2,cv2.LINE_AA)\n",
    "        for box in les_box:\n",
    "            cv2.rectangle(\n",
    "                im, \n",
    "                (box.x_min, box.y_min), \n",
    "                (box.x_max, box.y_max),\n",
    "                (255, 0, 0),\n",
    "                3\n",
    "            )\n",
    "\n",
    "        # write image to video\n",
    "        video.write(im)\n",
    "    video.release()\n",
    "    print(\"Done\" + \" \"*20)\n",
    "    \n",
    "    return les_whole_box_inertia\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Interface:\n",
    "    def __init__(self, data_root=data_root, back_sub_folder_path=BACK_SUB_FOLDER_PATH):\n",
    "        self.dataset_path = data_root\n",
    "        self.dataset_backsub_path = back_sub_folder_path\n",
    "        self.les_im_path = self.get_dataset_im_path(self.dataset_path)\n",
    "        self.les_im_backsub_path = self.get_dataset_im_path(self.dataset_backsub_path)\n",
    "    \n",
    "    def get_dataset_im_path(self, path):\n",
    "        \"\"\"\n",
    "        Get images path using glob\n",
    "        :param path: string, dataset folder\n",
    "        :return les_im_path: list of string, lsit sorted of every .jpg file in the dataset\n",
    "        \"\"\"\n",
    "        les_im_path = glob.glob(path + \"/*.jpg\")\n",
    "        les_im_path.sort()\n",
    "        return les_im_path\n",
    "    \n",
    "    def test_hog(self):\n",
    "        test_im = self.les_im_path[0]\n",
    "        hog(test_im)\n",
    "    \n",
    "    def background_substraction(self):\n",
    "        background_substraction(\n",
    "            self.les_im_path, \n",
    "            video_name=\"backgroud_substraction\", \n",
    "            back_sub_folder=self.dataset_backsub_path\n",
    "        )\n",
    "        self.les_im_backsub_path = self.get_dataset_im_path(self.dataset_backsub_path)\n",
    "        \n",
    "    def test_apply_box_to_video(self):\n",
    "        apply_box_to_video(self.les_im_path, self.les_im_backsub_path)\n",
    "\n",
    "tester = Interface()\n",
    "# tester.background_substraction()\n",
    "# tester.test_apply_box_to_video()\n",
    "# tester.test_disp_im()\n",
    "# tester.test_hog()\n",
    "# tester.background_substraction()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pedestrians(data_root, _W, _H, _N):\n",
    "    ''' Return a list of bounding boxes in the format frame, bb_id, x,y,dx,dy '''\n",
    "    \n",
    "    if not os.path.isdir(BACK_SUB_FOLDER_PATH):\n",
    "        # Generate back sub folder\n",
    "        pass\n",
    "    \n",
    "    interface = Interface(data_root, BACK_SUB_FOLDER_PATH)\n",
    "    # print(interface.les_im_path)\n",
    "    \n",
    "    les_wholes_box_id = apply_box_to_video(\n",
    "        les_im_path=interface.les_im_path, \n",
    "        les_im_backsub_path=interface.les_im_backsub_path,\n",
    "        video_name=\"apply_box\")\n",
    "    \n",
    "    # Putting in format asked by evaluation function\n",
    "    les_pedestrians = []\n",
    "    for id_frame, frame_boxes in enumerate(les_wholes_box_id):\n",
    "        for id_box, box in enumerate(frame_boxes):\n",
    "            pedestrian = [id_frame+1, id_box+1, box.x_min, box.y_min, box.x_max-box.x_min, box.y_max-box.y_min]\n",
    "            les_pedestrians.append(pedestrian)\n",
    "    \n",
    "    return les_pedestrians"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N.Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gt_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c1c93f0cea2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mSCORING\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mSCORING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mgt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_gt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mcheck_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m309\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mshow_annotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gt_path' is not defined"
     ]
    }
   ],
   "source": [
    "SCORING = True\n",
    "if SCORING:\n",
    "    gt = read_gt(gt_path)\n",
    "    check_id = 309\n",
    "    show_annotation(gt, check_id)\n",
    "\n",
    "    print('A perfect score... {}'.format(evaluate_solution(gt, gt, _N)))\n",
    "\n",
    "    # your solution will be tested simply by changing the dataset\n",
    "    # and changing the module, i.e., the following has to work \n",
    "    # with simply using your module \n",
    "    sol = pedestrians(data_root, _W, _H, _N)\n",
    "    print('A great score! {}'.format(evaluate_solution(sol, gt, _N)))\n",
    "    show_annotation(sol, check_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import struct\n",
    "\n",
    "def read_seq(path):\n",
    "    \n",
    "    def read_header(ifile):\n",
    "        feed = ifile.read(4)\n",
    "        norpix = ifile.read(24)\n",
    "        version = struct.unpack('@i', ifile.read(4))\n",
    "        length = struct.unpack('@i', ifile.read(4))\n",
    "        assert(length != 1024)\n",
    "        descr = ifile.read(512)\n",
    "        params = [struct.unpack('@i', ifile.read(4))[0] for i in range(0,9)]\n",
    "        fps = struct.unpack('@d', ifile.read(8))\n",
    "        # skipping the rest\n",
    "        ifile.read(432)\n",
    "        image_ext = {100:'raw', 102:'jpg',201:'jpg',1:'png',2:'png'}\n",
    "        return {'w':params[0],'h':params[1],\n",
    "                'bdepth':params[2],\n",
    "                'ext':image_ext[params[5]],\n",
    "                'format':params[5],\n",
    "                'size':params[4],\n",
    "                'true_size':params[8],\n",
    "                'num_frames':params[6]}\n",
    "    \n",
    "    ifile = open(path, 'rb')\n",
    "    params = read_header(ifile)\n",
    "    bytes = open(path, 'rb').read()\n",
    "\n",
    "    # this is freaking magic, but it works\n",
    "    extra = 8\n",
    "    s = 1024\n",
    "    seek = [0]*(params['num_frames']+1)\n",
    "    seek[0] = 1024\n",
    "    \n",
    "    images = []\n",
    "    \n",
    "    for i in range(0, params['num_frames']-1):\n",
    "        tmp = struct.unpack_from('@I', bytes[s:s+4])[0]\n",
    "        s = seek[i] + tmp + extra\n",
    "        if i == 0:\n",
    "            val = struct.unpack_from('@B', bytes[s:s+1])[0]\n",
    "            if val != 0:\n",
    "                s -= 4\n",
    "            else:\n",
    "                extra += 8\n",
    "                s += 8\n",
    "        seek[i+1] = s\n",
    "        nbytes = struct.unpack_from('@i', bytes[s:s+4])[0]\n",
    "        I = bytes[s+4:s+nbytes]\n",
    "        \n",
    "        tmp_file = '/tmp/img%d.jpg' % i\n",
    "        open(tmp_file, 'wb+').write(I)\n",
    "        \n",
    "        img = cv2.imread(tmp_file)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        images.append(img)\n",
    "    return images\n",
    "\n",
    "# a = read_seq(\"dataset/set00/V000.seq\")[200]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
