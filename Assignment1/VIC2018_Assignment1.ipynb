{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# À RENDRE LE 7 FÉVRIER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA3315: Introduction to Visual Computing\n",
    "## Assignment 1\n",
    "\n",
    "This assignment has two problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the required libraries first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "#import Image\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Canny edge detector \n",
    "\n",
    "For the first problem, we will implement our own Canny edge detector. Recall that the Canny edge detector consists of the following steps:\n",
    "* Smoothing the image using a Gaussian filter\n",
    "* Computing the gradient of the image&mdash;magnitude and direction&mdash;using the Sobel operator\n",
    "* Non-maximum suppression using the gradient's magnitude and direction\n",
    "* Double thresholding\n",
    "* Edge connectivity using hysterisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A Smoothing\n",
    "\n",
    "This standard smoothing operation can be implemented using the `gaussian_filter` function found in `sklearn.ndimage`. \n",
    "Alternatively, you can use the following Gaussian filter: \n",
    "\n",
    "`G = np.array([[2, 4,  5,  2,  2],\n",
    "               [4, 9,  12, 9,  4],\n",
    "               [5, 12, 15, 12, 5],\n",
    "               [4, 9,  12, 9,  4],\n",
    "               [2, 4,  5,  4,  2]]) / 156;`\n",
    "\n",
    "#### 1.B Gradients\n",
    "\n",
    "Use the Sobel operators to compute $g_x$ and $g_y$. The magnitude and direction of the gradient can be computed as \n",
    "$\\sqrt{g_x^2 + g_y^2}$, and $\\arctan\\left(\\frac{g_y}{g_x}\\right)$\n",
    "\n",
    "#### 1.C Non-maximum suppression\n",
    "\n",
    "We will take a simplistic approach to non-maximum suppression. First, we quantise the gradient directions into four values&mdash;$0$, $\\frac{\\pi}{4}$, $\\frac{\\pi}{2}$, and $\\frac{3\\pi}{4}$. Next, we suppress gradients at all points that are not greater than the two neighbours found when moving in the direction perpendicular to the edge.\n",
    "\n",
    "#### 1.D Doule thresholding\n",
    "\n",
    "Double thresholding can be implemented by fixing two thresholds, `lo` and `hi`. Accordingly, we will have two *levels* of gradient magnitudes&mdash;*weak* and *strong*. Pixels where the magnitude of the gradient is greater than high will be designated *strong* points, while those where it lies between `lo` and `high` will be designated *weak*. \n",
    "\n",
    "#### 1.E Edge connectivity\n",
    "\n",
    "Finally, we decide on edge connectivity as follows: \n",
    "* All pixels with strong gradients belong to edges, termed *definite edges*.\n",
    "* All pixels with weak gradients belong to edges only if they are connected to definite edges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a template for the Canny edge detector. Your task is to complete this function, and write any supporting functions necessary. You are, of course, free to diverge from this template, if you so wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian_smoothing(img):\n",
    "    # img_trans =cv2.GaussianBlur(img, (5, 5), 0)\n",
    "    img_trans = ndimage.gaussian_filter(img, 3)\n",
    "    return img_trans\n",
    "\n",
    "def gradient(smoothed):\n",
    "    # Horizontal derivative, axis x, 0\n",
    "    gx = ndimage.sobel(smoothed, 0)\n",
    "    # Vertical derivative, axis y, 1\n",
    "    gy = ndimage.sobel(smoothed, 1)\n",
    "    \n",
    "    # print(gx.shape)\n",
    "    # print(gy.shape)\n",
    "    \n",
    "    magnitude = np.sqrt(np.power(gx, 2) + np.power(gy, 2))\n",
    "    direction = np.arctan(gx/gy)\n",
    "    return magnitude, direction\n",
    "\n",
    "def non_maximum_suppression(g_magnitude, g_dir):\n",
    "    \n",
    "    # Cadran, directions, that are evaluated\n",
    "    quant_grad_direc = {'0' : [], \n",
    "                        'pi/4' : [], \n",
    "                        'pi/2' : [], \n",
    "                        '3pi/4' : []}\n",
    "    \n",
    "    # Thresold to approximate pi results\n",
    "    thresold = 0.0001\n",
    "    # Exploring the directions\n",
    "    for candidate_direction in g_dir:\n",
    "        print(candidate_direction)\n",
    "        # Selection which direction to evaluate\n",
    "        for cadran in quant_grad_direc:\n",
    "            # Affecting the value of the direction in value_cadran\n",
    "            if cadran == '0':\n",
    "                value_cadran = 0\n",
    "            elif cadran == 'pi/4':\n",
    "                value_cadran = np.pi/4\n",
    "            elif cadran == 'pi/2':\n",
    "                value_cadran = np.pi/2\n",
    "            elif cadran == '3pi/4':\n",
    "                value_cadran = 3*np.pi/4\n",
    "            else:\n",
    "                raise ValueError(\"Unknow value of cadran\")\n",
    "                \n",
    "            if value_cadran - thresold <= candidate_direction and candidate_direction <= value_cadran + thresold:\n",
    "                quant_grad_direc[cadran].append(candidate_direction)\n",
    "    print(quant_grad_direc)\n",
    "\n",
    "def double_thresholding(g_max):\n",
    "    pass\n",
    "\n",
    "def connectivity(thresh_img):\n",
    "    pass\n",
    "\n",
    "def canny_edge_detector(img, thresh_lo=0.1, thresh_hi=0.2):\n",
    "    \"\"\"\n",
    "    The Canny edge detector.\n",
    "    \n",
    "    Inputs:\n",
    "        img              The input image\n",
    "        thresh_lo        The fraction of the maximum gradient magnitude which will \n",
    "                         be considered the lo threshold. \n",
    "        thresh_hi        The fraction of the maximum gradient magnitude which will\n",
    "                         be considered the hi threshold. Ideally should be 2x to 3x \n",
    "                         thresh_lo.\n",
    "                         \n",
    "    Outputs: \n",
    "        edge_img         A binary image, with pixels lying on edges marked with a 1, \n",
    "                         and others with a 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Smooth the image first. \n",
    "    smoothed             = gaussian_smoothing(img)\n",
    "    \n",
    "    # Find gradient magnitude and direction\n",
    "    g_magnitude, g_dir   = gradient(smoothed)\n",
    "    \n",
    "    # Non-maximum suppression\n",
    "    g_max                = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    \n",
    "    # Double thresholding\n",
    "    thresh_img           = double_thresholding(g_max)\n",
    "    \n",
    "    # Final edge connectivity\n",
    "    edge_img             = connectivity(thresh_img)\n",
    "    \n",
    "    # Return the result\n",
    "    return edge_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the code on a sample image&mdash;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.         1.44982133 1.35673564 1.26339885 1.15442179 1.09759487\n",
      " 1.08500044 1.12327635 1.24192    1.38095349 0.         0.\n",
      " 0.         0.         0.         1.44982133 1.41459882 1.41459882\n",
      " 1.47658784 0.78933515 0.00444442 0.01522725 0.02272336 0.02438541\n",
      " 0.02438541 0.01714118 0.00534754 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.01030891\n",
      " 0.0185164  0.0192284  0.02272336 0.01587168 0.         0.\n",
      " 0.         0.         0.         0.00401604 0.46364761 0.06656816\n",
      " 0.         0.         1.48084365 1.51157711 1.5588447  0.7894304\n",
      " 0.81018647 0.82756724 0.85052333 0.87444775 0.89405938 0.9041035\n",
      " 0.91372139 0.91764921 0.91199029 0.90146605 0.87684545 0.85823048\n",
      " 0.848605   0.83063477 0.81384577 0.80968489 0.80547579 0.80547579\n",
      " 0.79734979 0.78935071 0.78933515        nan        nan 1.55903216\n",
      " 1.5550496  1.56687478        nan 0.78539816 0.78935071 0.78933515\n",
      "        nan        nan        nan 1.55903216 1.5550496  1.56687478\n",
      "        nan 0.78539816 0.78146118 0.78539816 0.79336612 0.78935071\n",
      " 0.7893664  0.79339799 0.79339799 0.78539816 0.78139818 0.78539816\n",
      " 0.78539816 0.78539816 0.78539816 0.79349515 0.79749435 0.79343012\n",
      " 0.7894304  0.78539816 0.78539816 0.78947977 0.78946318 0.78539816\n",
      " 0.78539816 0.78539816 0.79352807 0.79352807 0.79352807 0.79352807\n",
      " 0.79352807 0.79352807 0.79349515 0.79754332 0.7894304  0.79349515\n",
      " 0.79749435 0.79339799 0.8015258  0.8015258  0.80146104 0.80547579\n",
      " 0.80547579 0.8053955  0.         0.         0.         0.00395255\n",
      " 0.01185715 1.57079633 1.57079633 1.57079633 0.78539816 0.32175055\n",
      " 0.78539816 1.24904577 1.57079633 0.78539816 0.78539816 0.78539816\n",
      " 0.78539816 0.78539816 0.40489179 0.46364761 0.46364761 0.14189705\n",
      " 0.         0.19739556 0.46364761 0.14189705 0.                nan\n",
      "        nan        nan 0.         0.         0.         0.00401604\n",
      " 0.00793634 0.00392155        nan 0.         0.         0.\n",
      " 0.         0.         0.         0.19739556 0.46364761 0.32175055\n",
      " 0.78539816 1.24904577 1.57079633 1.57079633 1.57079633 0.01587168\n",
      " 0.01587168 0.01976027 0.02380503 0.02380503 0.02810505 0.03173537\n",
      " 0.02744409 1.03037683 0.24497866 0.12435499 0.08314123 0.05875582\n",
      " 0.06165017 0.08620557 0.11065722 0.16514868 0.5880026  0.03388533\n",
      " 0.03771795 0.04079368 0.04164258 0.03516138 0.02369225 0.01321509\n",
      " 0.0041152  0.                nan 0.         0.         0.\n",
      " 0.         0.         1.55903216 1.5550496  1.56687478        nan\n",
      " 0.         0.00401604 0.00806434 0.00404856 0.         0.00414935\n",
      " 0.01224429 0.01612763 0.01612763 0.02007762 0.02380503 0.02380503\n",
      " 0.02810505 0.03224688 0.03224688 0.03277514 0.033321   0.033321\n",
      " 0.033321   0.03277514 0.03277514 0.0283325  0.02380503 0.02380503\n",
      " 0.01960533 1.57079633 1.57079633 1.57079633 1.57079633 0.01176416\n",
      " 0.00392155 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.                nan\n",
      " 0.         0.                nan 0.         0.         0.78539816\n",
      " 0.46364761 0.32175055 0.         0.         0.78539816 0.46364761\n",
      " 0.32175055        nan        nan 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         1.54335224\n",
      " 1.5550496  1.56687478 0.         0.                nan 0.\n",
      " 0.         0.         0.                nan        nan        nan\n",
      " 0.         0.         0.         0.                nan        nan\n",
      "        nan        nan        nan 0.         0.         0.\n",
      " 0.         0.                nan 0.         0.                nan\n",
      "        nan 0.         0.                nan 0.         0.\n",
      "        nan        nan        nan 0.         0.         0.\n",
      " 0.                nan        nan        nan        nan 0.\n",
      " 0.         0.         0.                nan 0.         0.\n",
      "        nan        nan 0.         0.         0.         0.\n",
      " 1.55903216 1.5550496  1.56687478        nan        nan        nan\n",
      "        nan 0.         0.                nan 0.         0.\n",
      "        nan        nan        nan        nan        nan 0.\n",
      " 0.         0.         0.                nan        nan        nan\n",
      "        nan 0.         0.                nan 0.         0.\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan 0.\n",
      " 0.         0.         0.                nan 0.         0.\n",
      "        nan        nan 0.00395255 0.00793634 0.00392155        nan\n",
      "        nan        nan        nan 0.         0.                nan\n",
      "        nan        nan 0.78539816 0.46364761 0.32175055 0.78539816\n",
      " 0.46364761 0.32175055        nan        nan 0.78539816 1.24904577\n",
      " 1.57079633 0.01176416 0.00392155        nan        nan        nan\n",
      "        nan        nan 0.         0.                nan        nan\n",
      " 0.         0.                nan        nan        nan        nan\n",
      " 0.         0.                nan 0.78539816 0.78935071 0.78933515\n",
      "        nan        nan 0.78539816 1.24904577 0.78539816 0.32175055\n",
      "        nan 0.78539816 1.24904577 0.78539816 0.32175055        nan\n",
      " 0.         0.00401604 0.01204761 0.01214515 0.00404856 0.\n",
      " 0.         0.         0.                nan        nan        nan\n",
      "        nan        nan        nan        nan 1.55903216 1.5550496\n",
      " 1.56687478        nan        nan        nan        nan        nan\n",
      "        nan 0.78539816 0.78935071 0.78933515        nan        nan\n",
      "        nan        nan        nan 0.         0.                nan\n",
      " 0.         0.         1.55903216 1.5550496  1.5550496  1.55893917\n",
      " 1.56684378 1.57079633 0.78935071 0.78935071 0.78935071 0.79734979\n",
      " 0.80547579 0.81361648 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.                nan        nan        nan        nan\n",
      "        nan        nan 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.19739556 0.46364761 0.14189705 0.         0.78539816 1.57079633\n",
      " 0.00392155        nan 0.         0.         0.         0.\n",
      " 0.         0.                nan 0.         0.                nan\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.00401604 0.00793634 0.00392155        nan        nan 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.                nan 0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.19739556 0.46364761 0.32175055        nan        nan 0.78539816\n",
      " 0.24497866 0.06656816 0.         0.03997869 0.11942893 0.19739556\n",
      " 0.32175055 0.78539816 0.00819654 0.00847437 0.00425529 0.\n",
      " 0.         0.         0.         0.         0.                nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan 0.00395255 0.00793634\n",
      " 0.00392155 0.         0.         0.         0.         0.00395255\n",
      " 0.01185715 1.57079633 1.57079633 1.57079633]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/home/paul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:16: RuntimeWarning: invalid value encountered in true_divide\n",
      "  app.launch_new_instance()\n",
      "/home/paul/.local/lib/python3.6/site-packages/ipykernel_launcher.py:46: RuntimeWarning: invalid value encountered in greater_equal\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-429a1024d0fe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mimg\u001b[0m   \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_RGB2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcanny_edge_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-609630888787>\u001b[0m in \u001b[0;36mcanny_edge_detector\u001b[0;34m(img, thresh_lo, thresh_hi)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;31m# Non-maximum suppression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m     \u001b[0mg_max\u001b[0m                \u001b[0;34m=\u001b[0m \u001b[0mnon_maximum_suppression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg_magnitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;31m# Double thresholding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-609630888787>\u001b[0m in \u001b[0;36mnon_maximum_suppression\u001b[0;34m(g_magnitude, g_dir)\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Unknow value of cadran\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mvalue_cadran\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthresold\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcandidate_direction\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcandidate_direction\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mvalue_cadran\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mthresold\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0mquant_grad_direc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcadran\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_direction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquant_grad_direc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "img   = cv2.imread('valve.png')\n",
    "img   = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "edges = canny_edge_detector(img)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Found edges')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stitching two images\n",
    "\n",
    "For this problem, you are given two images&mdash;`left.png` and `right.png`, which were extracted from a bigger image. All we know is that `left.png` lies to the left and a bit above of `right.png`, and there is an overlapping region between the two. Your task will be to *stitch* these images together so that you can form a bigger image out of two smaller images. \n",
    "\n",
    "Let us load the images first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img   = cv2.imread('left.png')\n",
    "left_img   = cv2.cvtColor(left_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "right_img  = cv2.imread('right.png')\n",
    "right_img  = cv2.cvtColor(right_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(left_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(right_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to solve this problem using the Harris corner detector and the RANdom SAmple Consensus (RANSAC) algorithm. \n",
    "\n",
    "The steps are the following&mdash;\n",
    "* Find corner points in both images using the Harris corner detector. \n",
    "* Choose a random pair of points&mdash;one from the left image, and the other from the right. \n",
    "* We will assume that this pair represents the same location in the scene in both images. This gives a translation vector, so the we can superimpose this point in the right image onto the left image.\n",
    "* The translation gives us an overlapping region, which can be given a similarity score. \n",
    "* If we keep choosing this pair of points randomly, we can keep improving our similarity score until we have found the best match. \n",
    "\n",
    "Your task now is the complete the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(left, right, max_tries=1000):\n",
    "    # Find corner points\n",
    "    corners_left  = harris_corner_detector(left)\n",
    "    corners_right = harris_corner_detector(right)\n",
    "    \n",
    "    best_error = 255*left.shape[0]*left.shape[1]\n",
    "    best_trans = None\n",
    "    \n",
    "    for n_try in range(max_tries):\n",
    "        # Choose two points randomly\n",
    "        c_left, c_right  = find_random_pair(corners_left, corners_right)\n",
    "        \n",
    "        # Get translation vector\n",
    "        x_trans, y_trans = find_translation_vector(c_left, c_right)\n",
    "        \n",
    "        # Compute resulting error. \n",
    "        this_error       = compute_error( ... )\n",
    "        \n",
    "        if this_error < best_error:\n",
    "            best_error   = this_error\n",
    "            best_trans   = x_trans, y_trans\n",
    "            \n",
    "    stitched_image = np.zeros(stiched_image_shape)\n",
    "    return stitched_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark.** Note that in this simplified problem setting, we assumed only translations along $x-$ and $y-$axes. However, in a real-world scenario, we can expect any affine transformation and/or viewpoint differences between the two images. This means we can no longer decide correspondences using only one pair of points. Can you think of a strategy that can be employed in such a scenario? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
