{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MA3315: Introduction to Visual Computing\n",
    "## Assignment 1\n",
    "\n",
    "This assignment has two problems. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us load the required libraries first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import cv2\n",
    "import numpy as np\n",
    "import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. The Canny edge detector \n",
    "\n",
    "For the first problem, we will implement our own Canny edge detector. Recall that the Canny edge detector consists of the following steps:\n",
    "* Smoothing the image using a Gaussian filter\n",
    "* Computing the gradient of the image&mdash;magnitude and direction&mdash;using the Sobel operator\n",
    "* Non-maximum suppression using the gradient's magnitude and direction\n",
    "* Double thresholding\n",
    "* Edge connectivity using hysterisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.A Smoothing\n",
    "\n",
    "This standard smoothing operation can be implemented using the `gaussian_filter` function found in `sklearn.ndimage`. \n",
    "Alternatively, you can use the following Gaussian filter: \n",
    "\n",
    "`G = np.array([[2, 4,  5,  2,  2],\n",
    "               [4, 9,  12, 9,  4],\n",
    "               [5, 12, 15, 12, 5],\n",
    "               [4, 9,  12, 9,  4],\n",
    "               [2, 4,  5,  4,  2]]) / 156;`\n",
    "\n",
    "#### 1.B Gradients\n",
    "\n",
    "Use the Sobel operators to compute $g_x$ and $g_y$. The magnitude and direction of the gradient can be computed as \n",
    "$\\sqrt{g_x^2 + g_y^2}$, and $\\arctan\\left(\\frac{g_y}{g_x}\\right)$\n",
    "\n",
    "#### 1.C Non-maximum suppression\n",
    "\n",
    "We will take a simplistic approach to non-maximum suppression. First, we quantise the gradient directions into four values&mdash;$0$, $\\frac{\\pi}{4}$, $\\frac{\\pi}{2}$, and $\\frac{3\\pi}{2}$. Next, we suppress gradients at all points that are not greater than the two neighbours found when moving in the direction perpendicular to the edge.\n",
    "\n",
    "#### 1.D Doule thresholding\n",
    "\n",
    "Double thresholding can be implemented by fixing two thresholds, `lo` and `hi`. Accordingly, we will have two *levels* of gradient magnitudes&mdash;*weak* and *strong*. Pixels where the magnitude of the gradient is greater than high will be designated *strong* points, while those where it lies between `lo` and `high` will be designated *weak*. \n",
    "\n",
    "#### 1.E Edge connectivity\n",
    "\n",
    "Finally, we decide on edge connectivity as follows: \n",
    "* All pixels with strong gradients belong to edges, termed *definite edges*.\n",
    "* All pixels with weak gradients belong to edges only if they are connected to definite edges. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is a template for the Canny edge detector. Your task is to complete this function, and write any supporting functions necessary. You are, of course, free to diverge from this template, if you so wish. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def canny_edge_detector(img, thresh_lo=0.1, thresh_hi=0.2):\n",
    "    \"\"\"\n",
    "    The Canny edge detector.\n",
    "    \n",
    "    Inputs:\n",
    "        img              The input image\n",
    "        thresh_lo        The fraction of the maximum gradient magnitude which will \n",
    "                         be considered the lo threshold. \n",
    "        thresh_hi        The fraction of the maximum gradient magnitude which will\n",
    "                         be considered the hi threshold. Ideally should be 2x to 3x \n",
    "                         thresh_lo.\n",
    "                         \n",
    "    Outputs: \n",
    "        edge_img         A binary image, with pixels lying on edges marked with a 1, \n",
    "                         and others with a 0.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Smooth the image first. \n",
    "    smoothed             = gaussian_smoothing(img)\n",
    "    \n",
    "    # Find gradient magnitude and direction\n",
    "    g_magnitude, g_dir   = gradient(smoothed)\n",
    "    \n",
    "    # Non-maximum suppression\n",
    "    g_max                = non_maximum_suppression(g_magnitude, g_dir)\n",
    "    \n",
    "    # Double thresholding\n",
    "    thresh_img           = double_thresholding(g_max)\n",
    "    \n",
    "    # Final edge connectivity\n",
    "    edge_img             = connectivity(thresh_img)\n",
    "    \n",
    "    # Return the result\n",
    "    return edge_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now test the code on a sample image&mdash;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img   = cv2.imread('valve.png')\n",
    "img   = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "edges = canny_edge_detector(img)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(img)\n",
    "plt.axis('off')\n",
    "plt.title('Original')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(edges)\n",
    "plt.axis('off')\n",
    "plt.title('Found edges')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Stitching two images\n",
    "\n",
    "For this problem, you are given two images&mdash;`left.png` and `right.png`, which were extracted from a bigger image. All we know is that `left.png` lies to the left and a bit above of `right.png`, and there is an overlapping region between the two. Your task will be to *stitch* these images together so that you can form a bigger image out of two smaller images. \n",
    "\n",
    "Let us load the images first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_img   = cv2.imread('left.png')\n",
    "left_img   = cv2.cvtColor(left_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "right_img  = cv2.imread('right.png')\n",
    "right_img  = cv2.cvtColor(right_img, cv2.COLOR_RGB2GRAY)\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(left_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Left')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(right_img, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.title('Right')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try to solve this problem using the Harris corner detector and the RANdom SAmple Consensus (RANSAC) algorithm. \n",
    "\n",
    "The steps are the following&mdash;\n",
    "* Find corner points in both images using the Harris corner detector. \n",
    "* Choose a random pair of points&mdash;one from the left image, and the other from the right. \n",
    "* We will assume that this pair represents the same location in the scene in both images. This gives a translation vector, so the we can superimpose this point in the right image onto the left image.\n",
    "* The translation gives us an overlapping region, which can be given a similarity score. \n",
    "* If we keep choosing this pair of points randomly, we can keep improving our similarity score until we have found the best match. \n",
    "\n",
    "Your task now is the complete the following code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stitch_images(left, right, max_tries=1000):\n",
    "    # Find corner points\n",
    "    corners_left  = harris_corner_detector(left)\n",
    "    corners_right = harris_corner_detector(right)\n",
    "    \n",
    "    best_error = 255*left.shape[0]*left.shape[1]\n",
    "    best_trans = None\n",
    "    \n",
    "    for n_try in range(max_tries):\n",
    "        # Choose two points randomly\n",
    "        c_left, c_right  = find_random_pair(corners_left, corners_right)\n",
    "        \n",
    "        # Get translation vector\n",
    "        x_trans, y_trans = find_translation_vector(c_left, c_right)\n",
    "        \n",
    "        # Compute resulting error. \n",
    "        this_error       = compute_error( ... )\n",
    "        \n",
    "        if this_error < best_error:\n",
    "            best_error   = this_error\n",
    "            best_trans   = x_trans, y_trans\n",
    "            \n",
    "    stitched_image = np.zeros(stiched_image_shape)\n",
    "    return stitched_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remark.** Note that in this simplified problem setting, we assumed only translations along $x-$ and $y-$axes. However, in a real-world scenario, we can expect any affine transformation and/or viewpoint differences between the two images. This means we can no longer decide correspondences using only one pair of points. Can you think of a strategy that can be employed in such a scenario? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
